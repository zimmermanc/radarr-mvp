groups:
- name: unified-radarr.rules
  rules:
  # Application Health Alerts
  - alert: RadarrMVPDown
    expr: up{job="unified-radarr"} == 0
    for: 5m
    labels:
      severity: critical
      component: application
    annotations:
      summary: "Radarr MVP application is down"
      description: "Radarr MVP has been down for more than 5 minutes."
      runbook_url: "https://runbooks.example.com/unified-radarr-down"

  - alert: RadarrMVPHighLatency
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="unified-radarr"}[5m])) > 2
    for: 10m
    labels:
      severity: warning
      component: application
    annotations:
      summary: "High latency on Radarr MVP"
      description: "95th percentile latency is {{ $value }}s for more than 10 minutes."

  - alert: RadarrMVPHighErrorRate
    expr: rate(http_requests_total{job="unified-radarr",status=~"5.."}[5m]) / rate(http_requests_total{job="unified-radarr"}[5m]) > 0.05
    for: 5m
    labels:
      severity: critical
      component: application
    annotations:
      summary: "High error rate on Radarr MVP"
      description: "Error rate is {{ $value | humanizePercentage }} for more than 5 minutes."

  # Database Alerts
  - alert: PostgreSQLDown
    expr: up{job="postgres-exporter"} == 0
    for: 5m
    labels:
      severity: critical
      component: database
    annotations:
      summary: "PostgreSQL is down"
      description: "PostgreSQL has been down for more than 5 minutes."

  - alert: PostgreSQLHighConnections
    expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80
    for: 10m
    labels:
      severity: warning
      component: database
    annotations:
      summary: "PostgreSQL high connection usage"
      description: "PostgreSQL connection usage is {{ $value }}% for more than 10 minutes."

  - alert: PostgreSQLSlowQueries
    expr: rate(pg_stat_statements_mean_time_seconds[5m]) > 1
    for: 15m
    labels:
      severity: warning
      component: database
    annotations:
      summary: "PostgreSQL slow queries detected"
      description: "Average query time is {{ $value }}s for more than 15 minutes."

  - alert: PostgreSQLDiskSpaceUsage
    expr: (pg_database_size_bytes / (1024^3)) > 80
    for: 30m
    labels:
      severity: warning
      component: database
    annotations:
      summary: "PostgreSQL high disk usage"
      description: "Database size is {{ $value }}GB, approaching storage limits."

  # Redis Alerts
  - alert: RedisDown
    expr: up{job="redis-exporter"} == 0
    for: 5m
    labels:
      severity: critical
      component: cache
    annotations:
      summary: "Redis is down"
      description: "Redis has been down for more than 5 minutes."

  - alert: RedisHighMemoryUsage
    expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
    for: 10m
    labels:
      severity: warning
      component: cache
    annotations:
      summary: "Redis high memory usage"
      description: "Redis memory usage is {{ $value }}% for more than 10 minutes."

  - alert: RedisConnectionsHigh
    expr: redis_connected_clients > 100
    for: 15m
    labels:
      severity: warning
      component: cache
    annotations:
      summary: "Redis high connection count"
      description: "Redis has {{ $value }} connections for more than 15 minutes."

  # Infrastructure Alerts
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 15m
    labels:
      severity: warning
      component: infrastructure
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is {{ $value }}% on {{ $labels.instance }} for more than 15 minutes."

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
    for: 10m
    labels:
      severity: critical
      component: infrastructure
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is {{ $value }}% on {{ $labels.instance }} for more than 10 minutes."

  - alert: DiskSpaceUsage
    expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
    for: 30m
    labels:
      severity: warning
      component: infrastructure
    annotations:
      summary: "High disk usage detected"
      description: "Disk usage is {{ $value }}% on {{ $labels.instance }} mountpoint {{ $labels.mountpoint }}."

  - alert: KubernetesPodCrashLooping
    expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
    for: 5m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "Pod is crash looping"
      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting frequently."

  - alert: KubernetesPodNotReady
    expr: kube_pod_status_ready{condition="false"} == 1
    for: 10m
    labels:
      severity: warning
      component: kubernetes
    annotations:
      summary: "Pod not ready"
      description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been not ready for more than 10 minutes."

  # Business Logic Alerts
  - alert: DownloadQueueBacklog
    expr: radarr_download_queue_size > 100
    for: 30m
    labels:
      severity: warning
      component: business
    annotations:
      summary: "Download queue backlog"
      description: "Download queue has {{ $value }} items for more than 30 minutes."

  - alert: FailedDownloadsHigh
    expr: rate(radarr_downloads_failed_total[1h]) > 0.1
    for: 30m
    labels:
      severity: warning
      component: business
    annotations:
      summary: "High failed download rate"
      description: "Failed download rate is {{ $value }} per hour for more than 30 minutes."

  - alert: APIRateLimitApproaching
    expr: radarr_api_rate_limit_remaining < 100
    for: 15m
    labels:
      severity: warning
      component: external
    annotations:
      summary: "API rate limit approaching"
      description: "{{ $labels.api }} rate limit remaining: {{ $value }} requests."

  # Monitoring System Alerts
  - alert: PrometheusConfigurationReloadFailure
    expr: prometheus_config_last_reload_successful != 1
    for: 5m
    labels:
      severity: warning
      component: monitoring
    annotations:
      summary: "Prometheus configuration reload failed"
      description: "Prometheus configuration reload has failed."

  - alert: PrometheusTargetDown
    expr: up == 0
    for: 5m
    labels:
      severity: warning
      component: monitoring
    annotations:
      summary: "Prometheus target down"
      description: "{{ $labels.job }} target is down."